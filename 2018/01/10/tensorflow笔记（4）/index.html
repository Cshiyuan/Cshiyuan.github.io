<!DOCTYPE html>
<html lang='zh-CN'>

<head>
  <meta name="generator" content="Hexo 6.2.0">
  <meta charset="utf-8">
  

  <meta http-equiv='x-dns-prefetch-control' content='on' />
  <link rel='dns-prefetch' href='https://cdn.jsdelivr.net'>
  <link rel="preconnect" href="https://cdn.jsdelivr.net" crossorigin>
  <link rel='dns-prefetch' href='//unpkg.com'>

  <meta name="renderer" content="webkit">
  <meta name="force-rendering" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=Edge,chrome=1">
  <meta name="HandheldFriendly" content="True" >
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="theme-color" content="#f8f8f8">
  <title>tensorflow笔记（4） - C's Notebook</title>

  

  
    <meta name="description" content="一个简单的基于MNIST训练的CNN模型卷积神经网络包含输入层、隐藏层和输出层，隐藏层又包含卷积层和pooling层，图像输入到卷积神经网络后通过卷积来不断的提取特征，每提取一个特征就会增加一个feature map，pooling层也就是下采样，通常采用的是最大值pooling和平均值pooling，因为参数太多喽，所以通过pooling来稀疏参数，使我们的网络不至于太复杂。 好啦，既然你对卷积">
<meta property="og:type" content="article">
<meta property="og:title" content="tensorflow笔记（4）">
<meta property="og:url" content="https://cshiyuan.github.io/2018/01/10/tensorflow%E7%AC%94%E8%AE%B0%EF%BC%884%EF%BC%89/index.html">
<meta property="og:site_name" content="C&#39;s Notebook">
<meta property="og:description" content="一个简单的基于MNIST训练的CNN模型卷积神经网络包含输入层、隐藏层和输出层，隐藏层又包含卷积层和pooling层，图像输入到卷积神经网络后通过卷积来不断的提取特征，每提取一个特征就会增加一个feature map，pooling层也就是下采样，通常采用的是最大值pooling和平均值pooling，因为参数太多喽，所以通过pooling来稀疏参数，使我们的网络不至于太复杂。 好啦，既然你对卷积">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2018-01-10T05:16:59.000Z">
<meta property="article:modified_time" content="2022-05-23T08:43:39.083Z">
<meta property="article:author" content="shyiuanchen">
<meta name="twitter:card" content="summary">
  
  

  <!-- feed -->
  

  
    
<link rel="stylesheet" href="/css/main.css">

  

  

  
</head>

<body>
  




  <div class='l_body' id='start'>
    <aside class='l_left' layout='post'>
    


<header class="header">

<div class="logo-wrap"><a class="avatar" href="/about/"><div class="bg" style="opacity:0;background-image:url(https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.2/avatar/round/rainbow64@3x.webp);"></div><img no-lazy class="avatar" src="https://avatars.githubusercontent.com/u/11845557?s=96&v=4" onerror="javascript:this.classList.add('error');this.src='https://cdn.jsdelivr.net/gh/cdn-x/placeholder@1.0.1/image/2659360.svg';"></a><a class="title" href="/"><div class="main">C's Notebook</div><div class="sub cap">Hi! This is my technical notebook.</div></a></div>
<nav class="menu dis-select"></nav></header>

<div class="widgets">

<div class="widget-wrap single" id="toc"><div class="widget-header cap dis-select"><span class="name">本文目录</span></div><div class="widget-body fs14"><div class="doc-tree active"><ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E4%B8%80%E4%B8%AA%E7%AE%80%E5%8D%95%E7%9A%84%E5%9F%BA%E4%BA%8EMNIST%E8%AE%AD%E7%BB%83%E7%9A%84CNN%E6%A8%A1%E5%9E%8B"><span class="toc-text">一个简单的基于MNIST训练的CNN模型</span></a></li></ol></div></div></div>


</div>


    </aside>
    <div class='l_main'>
      

      

<div class="bread-nav fs12"><div id="breadcrumb"><a class="cap breadcrumb" href="/">主页</a><span class="sep"></span><a class="cap breadcrumb" href="/">文章</a><span class="sep"></span><a class="cap breadcrumb-link" href="/categories/Tensorflow/">Tensorflow</a></div><div id="post-meta">发布于&nbsp;<time datetime="2018-01-10T05:16:59.000Z">2018-01-10</time></div></div>

<article class='content md post'>
<h1 class="article-title"><span>tensorflow笔记（4）</span></h1>
<h3 id="一个简单的基于MNIST训练的CNN模型"><a href="#一个简单的基于MNIST训练的CNN模型" class="headerlink" title="一个简单的基于MNIST训练的CNN模型"></a>一个简单的基于MNIST训练的CNN模型</h3><p>卷积神经网络包含输入层、隐藏层和输出层，隐藏层又包含卷积层和pooling层，图像输入到卷积神经网络后通过卷积来不断的提取特征，每提取一个特征就会增加一个feature map，pooling层也就是下采样，通常采用的是最大值pooling和平均值pooling，因为参数太多喽，所以通过pooling来稀疏参数，使我们的网络不至于太复杂。</p>
<p>好啦，既然你对卷积神经网络已经有了大概的了解，下次课我们将通过代码来实现一个基于MNIST数据集的简单卷积神经网络。</p>
<pre class="language-Python" data-language="Python"><code class="language-Python">import tensorflow as tf
from tensorflow.examples.tutorials.mnist import input_data


def compute_accuracy(v_xs, v_ys):
    global prediction
    y_pre &#x3D; sess.run(prediction, feed_dict&#x3D;&#123;xs: v_xs, keep_prob: 1&#125;)
    correct_prediction &#x3D; tf.equal(tf.argmax(y_pre, 1), tf.argmax(v_ys, 1))
    accuracy &#x3D; tf.reduce_mean(tf.cast(correct_prediction, tf.float32))
    result &#x3D; sess.run(accuracy, feed_dict&#x3D;&#123;xs: v_xs, ys: v_ys, keep_prob: 1&#125;)
    return result


# 我们定义Weight变量，输入shape，返回变量的参数。其中我们使用tf.truncted_normal产生随机变量来进行初始化
def weight_variable(shape):
    initial &#x3D; tf.truncated_normal(shape, stddev&#x3D;0.1)
    return tf.Variable(initial)


# 同样的定义biase变量
# 输入shape ，返回变量的一些参数。其中我们使用tf.constant常量函数来进行初始化
def bias_variable(shape):
    initial &#x3D; tf.constant(0.1, shape&#x3D;shape)
    return tf.Variable(initial)


# 定义卷积，tf.nn.conv2d函数是tensorflow里面的二维卷积函数
# x是图片的所有参数，W是次卷积层的权重，然后定义步长strides&#x3D;[1,1,1,1]的值
# strides[0]和strides[3]的两个1是默认值
# 中间两个1代表padding时在x方向运动一步
# x方向运动一步，y方向运动一步，padding采用的方式是SAME
def conv2d(x, W):
    return tf.nn.conv2d(x, W, strides&#x3D;[1, 1, 1, 1], padding&#x3D;&#39;SAME&#39;)


# 定义池化pooling
# padding时，我们选的是一次一步，这样得到的图片尺寸没有变化
# 而我们希望压缩一下图片也就是参数能少一些从而减少系统复杂度
# 因此我们采用pooling来稀疏化参数，也就是卷积神经网络中所谓的下采样层。
# pooling 有两种，一种是最大值池化，一种是平均值池化，
# 本例采用的是最大值池化tf.max_pool()。
# 池化的核函数大小为2x2，因此ksize&#x3D;[1,2,2,1]，步长为2，因此strides&#x3D;[1,2,2,1]:
def max_pool_2x2(x):
    return tf.nn.max_pool(
        x, ksize&#x3D;[1, 2, 2, 1], strides&#x3D;[1, 2, 2, 1], padding&#x3D;&#39;SAME&#39;)


# 数据来源
mnist &#x3D; input_data.read_data_sets(&#39;MNIST_data&#39;, one_hot&#x3D;False)

# 定义输入的placeholder
xs &#x3D; tf.placeholder(tf.float32, [None, 784]) &#x2F; 255  # 28x28
ys &#x3D; tf.placeholder(tf.float32, [None, 10])

# -1代表先不考虑输入的图片例子多少这个维度
# 后面的1是channel的数量，因为我们输入的图片是黑白的，因此channel是1，例如如果是RGB图像，那么channel就是3。
x_image &#x3D; tf.reshape(xs, [-1, 28, 28, 1])

## conv1 layer --- start ##
# 建立卷积层
# 定义第一层卷积，先定义本层的Weight，本层我们的卷积层核patch的大小是5x5
# 因为channel是1，所有输入是1， 输出是32个featuremap
W_conv1 &#x3D; weight_variable([5, 5, 1, 32])

# 接着定义bias，它的大小是32个长度，因此我们传入它的shape为[32]
b_conv1 &#x3D; bias_variable([32])
# 第一个卷积层
# h_conv1&#x3D;conv2d(x_image,W_conv1)+b_conv1
# 同时我们对h_conv1进行非线性处理，也就是激活函数来处理喽，
# 这里我们用的是tf.nn.relu（修正线性单元）来处理，
# 要注意的是，因为采用了SAME的padding方式，
# 输出图片的大小没有变化依然是28x28，只是厚度变厚了，
# 因此现在的输出大小就变成了28x28x32
h_conv1 &#x3D; tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)

#最后我们再进行pooling的处理就ok啦，经过pooling的处理，输出大小就变为了14x14x32
h_pool1 &#x3D; max_pool_2x2(h_conv1)

## conv1 layer --- end ##

## conv2 layer --- start ##

# 接着呢，同样的形式我们定义第二层卷积，
# 本层我们的输入就是上一层的输出，本层我们的卷积核patch的大小是5x5，
# 有32个featuremap所以输入就是32，输出呢我们定为64
W_conv2 &#x3D; weight_variable([5, 5, 32, 64])
b_conv2 &#x3D; bias_variable([64])
# 接着我们就可以定义卷积神经网络的第二个卷积层，这时的输出的大小就是14x14x64
h_conv2 &#x3D; tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)
# 最后也是一个pooling处理，输出大小为7x7x64
h_pool2 &#x3D; max_pool_2x2(h_conv2)
# 建立全连接层
# 进入全连接层时，我们通过tf.reshape()将h_pool2的输出值从一个三维的变为一维的数据
# 表示先不考虑输入图片例子纬度，将上一个输出结果展平

## conv1 layer --- end ##

## fc1 layer --- start ##

# 此时weight_variable的shape输入就是第二个卷积层展平的输出大小7*7*64
# 后面输出的size我们继续扩大，定为1024
W_fc1 &#x3D; weight_variable([7 * 7 * 64, 1024])
b_fc1 &#x3D; bias_variable([1024])
#[n_sample, 7,7,64] -&gt;&gt; [n_samples. 7*6*64]
h_pool2_flat &#x3D; tf.reshape(h_pool2, [-1, 7 * 7 * 64])
# 然后将展平后的h_pool2_flat与本层的W_fc1相乘（注意这个时候不是卷积了）
h_fc1 &#x3D; tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)
# 定义dropout的placeholder，它是解决过拟合的有效手段
keep_prob &#x3D; tf.placeholder(tf.float32)
# 如果我们考虑过拟合的问题，可以加一个dropout的处理
h_fc1_drop &#x3D; tf.nn.dropout(h_fc1, keep_prob)

## fc1 layer --- end ##

## fc2 layer --- start ##

# 接下来我们就可以进行最后一层的构建了，好激动啊，输入是1024
W_fc2 &#x3D; weight_variable([1024, 10])
b_fc2 &#x3D; bias_variable([10])
# 然后呢，我们用softmax分类器（多分类，输出的是各个类的概率），对我们的输出进行分类
prediction &#x3D; tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)

## fc2 layer --- end ##

# 选优化方法
cross_entropy &#x3D; tf.reduce_mean(
    -tf.reduce_sum(ys * tf.log(prediction), reduction_indices&#x3D;[1]))  # loss

# 我们用tf.train.AdamOptimizer()作为我们的优化器进行优化，使我们的cross_entropy最小
train_step &#x3D; tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)

# 接着呢就是和之前视频讲的一样喽， 定义Session
sess &#x3D; tf.Session()

# 初始化变量
sess.run(tf.global_variables_initializer())

for i in range(1000):
    batch_xs, batch_ys &#x3D; mnist.train.next_batch(100)
    sess.run(
        train_step, feed_dict&#x3D;&#123;
            xs: batch_xs,
            ys: batch_ys,
            keep_prob: 0.5
        &#125;)
    if i % 50 &#x3D;&#x3D; 0:
        print(
            compute_accuracy(mnist.test.images[:1000],
                             mnist.test.labels[:1000]))

</code></pre>


<div class="article-footer reveal fs14"><section id="license"><div class="header"><span>许可协议</span></div><div class="body"><p>本文采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">署名-非商业性使用-相同方式共享 4.0 国际</a> 许可协议，转载请注明出处。</p>
</div></section></div>

</article>

<div class="related-wrap reveal" id="read-next"><section class="header cap theme"><span>接下来阅读</span></section><section class="body fs14"><a id="next" href="/2018/01/08/TensorFlow-Classification%E5%88%86%E7%B1%BB%E5%AD%A6%E4%B9%A0/">TensorFlow Classification分类学习<span class="note">较早</span></a><div class="line"></div><a id="prev" href="/2018/01/11/tensorflow%E7%AC%94%E8%AE%B0%EF%BC%885%EF%BC%89/">tensorflow笔记（5）<span class="note">较新</span></a></section></div>






  <div class='related-wrap md reveal' id="comments">
    <div class='cmt-title cap theme'>
      快来参与讨论吧
    </div>
    <div class='cmt-body beaudar'>
      

<svg class="loading" style="vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="2709"><path d="M832 512c0-176-144-320-320-320V128c211.2 0 384 172.8 384 384h-64zM192 512c0 176 144 320 320 320v64C300.8 896 128 723.2 128 512h64z" p-id="2710"></path></svg>

<div id="beaudar" repo="xaoxuu/blog-comments" issue-term="pathname" theme="preferred-color-scheme" input-position="top" comment-order="desc" loading="false" branch="main"></div>

    </div>
  </div>



      
<footer class="page-footer reveal fs12"><hr><div class="text"><p>本博客所有文章除特别声明外，均采用 <a target="_blank" rel="noopener" href="https://creativecommons.org/licenses/by-nc-sa/4.0/">CC BY-NC-SA 4.0</a> 许可协议，转载请注明出处。</p>
<p>本站由 <a href="https://cshiyuan.github.io/">@shyiuanchen</a> 创建，使用 <a target="_blank" rel="noopener" href="https://github.com/xaoxuu/hexo-theme-stellar/tree/1.7.0" title="v1.7.0">Stellar</a> 作为主题。</p>
</div></footer>

      <div class='float-panel mobile-only blur' style='display:none'>
  <button type='button' class='sidebar-toggle mobile' onclick='sidebar.toggle()'>
    <svg class="icon" style="width: 1em; height: 1em;vertical-align: middle;fill: currentColor;overflow: hidden;" viewBox="0 0 1024 1024" version="1.1" xmlns="http://www.w3.org/2000/svg" p-id="15301"><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 2.3 26.8 24.6 47.5 51.6 47.6h416.5v4z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15302"></path><path d="M566.407 808.3c26.9-0.1 49.3-20.8 51.6-47.6-1.9-27.7-23.9-49.7-51.6-51.6h-412.6c-28.2-1.4-52.6 19.5-55.5 47.6 1.9 27.7 23.9 49.7 51.6 51.6h416.5z m309.3-249.9c26.9-0.1 49.3-20.8 51.6-47.6-2.2-26.8-24.6-47.5-51.6-47.6h-721.9c-27.7-2.8-52.5 17.4-55.3 45.1-0.1 0.8-0.1 1.7-0.2 2.5 0.9 27.2 23.6 48.5 50.7 47.6H875.707z m-103.1-245.9c26.9-0.1 49.3-20.8 51.6-47.6-0.4-28.3-23.2-51.1-51.5-51.6h-618.9c-29.5-1.1-54.3 21.9-55.5 51.4v0.2c1.4 27.8 25.2 49.2 53 47.8 0.8 0 1.7-0.1 2.5-0.2h618.8z" p-id="15303"></path></svg>
  </button>
</div>

    </div>
  </div>
  <div class='scripts'>
    <script type="text/javascript">
  stellar = {
    // 懒加载 css https://github.com/filamentgroup/loadCSS
    loadCSS: (href, before, media, attributes) => {
      var doc = window.document;
      var ss = doc.createElement("link");
      var ref;
      if (before) {
        ref = before;
      } else {
        var refs = (doc.body || doc.getElementsByTagName("head")[0]).childNodes;
        ref = refs[refs.length - 1];
      }
      var sheets = doc.styleSheets;
      if (attributes) {
        for (var attributeName in attributes) {
          if (attributes.hasOwnProperty(attributeName)) {
            ss.setAttribute(attributeName, attributes[attributeName]);
          }
        }
      }
      ss.rel = "stylesheet";
      ss.href = href;
      ss.media = "only x";
      function ready(cb) {
        if (doc.body) {
          return cb();
        }
        setTimeout(function () {
          ready(cb);
        });
      }
      ready(function () {
        ref.parentNode.insertBefore(ss, before ? ref : ref.nextSibling);
      });
      var onloadcssdefined = function (cb) {
        var resolvedHref = ss.href;
        var i = sheets.length;
        while (i--) {
          if (sheets[i].href === resolvedHref) {
            return cb();
          }
        }
        setTimeout(function () {
          onloadcssdefined(cb);
        });
      };
      function loadCB() {
        if (ss.addEventListener) {
          ss.removeEventListener("load", loadCB);
        }
        ss.media = media || "all";
      }
      if (ss.addEventListener) {
        ss.addEventListener("load", loadCB);
      }
      ss.onloadcssdefined = onloadcssdefined;
      onloadcssdefined(loadCB);
      return ss;
    },

    // 从 butterfly 和 volantis 获得灵感
    loadScript: (src, opt) => new Promise((resolve, reject) => {
      var script = document.createElement('script');
      script.src = src;
      if (opt) {
        for (let key of Object.keys(opt)) {
          script[key] = opt[key]
        }
      } else {
        // 默认异步，如果需要同步，第二个参数传入 {} 即可
        script.async = true
      }
      script.onerror = reject
      script.onload = script.onreadystatechange = function() {
        const loadState = this.readyState
        if (loadState && loadState !== 'loaded' && loadState !== 'complete') return
        script.onload = script.onreadystatechange = null
        resolve()
      }
      document.head.appendChild(script)
    }),

    // https://github.com/jerryc127/hexo-theme-butterfly
    jQuery: (fn) => {
      if (typeof jQuery === 'undefined') {
        stellar.loadScript(stellar.plugins.jQuery).then(fn)
      } else {
        fn()
      }
    }
  };
  stellar.github = 'https://github.com/xaoxuu/hexo-theme-stellar/tree/1.7.0';
  stellar.config = {
    date_suffix: {
      just: '刚刚',
      min: '分钟前',
      hour: '小时前',
      day: '天前',
      month: '个月前',
    },
  };

  // required plugins (only load if needs)
  stellar.plugins = {
    jQuery: 'https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.min.js',
    sitesjs: '/js/plugins/sites.js',
    friendsjs: '/js/plugins/friends.js',
  };

  // optional plugins
  if ('true' == 'true') {
    stellar.plugins.lazyload = Object.assign({"enable":true,"js":"https://cdn.jsdelivr.net/npm/vanilla-lazyload@17.3.1/dist/lazyload.min.js","transition":"blur"});
  }
  if ('true' == 'true') {
    stellar.plugins.swiper = Object.assign({"enable":true,"css":"https://unpkg.com/swiper@6/swiper-bundle.min.css","js":"https://unpkg.com/swiper@6/swiper-bundle.min.js"});
  }
  if ('' == 'true') {
    stellar.plugins.scrollreveal = Object.assign({"enable":null,"js":"https://cdn.jsdelivr.net/npm/scrollreveal@4.0.9/dist/scrollreveal.min.js","distance":"8px","duration":500,"interval":100,"scale":1});
  }
  if ('true' == 'true') {
    stellar.plugins.preload = Object.assign({"enable":true,"service":"flying_pages","instant_page":"https://cdn.jsdelivr.net/gh/volantis-x/cdn-volantis@4.1.2/js/instant_page.js","flying_pages":"https://cdn.jsdelivr.net/gh/gijo-varghese/flying-pages@2.1.2/flying-pages.min.js"});
  }
  if ('true' == 'true') {
    stellar.plugins.fancybox = Object.assign({"enable":true,"js":"https://cdn.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.umd.js","css":"https://cdn.jsdelivr.net/npm/@fancyapps/ui@4.0/dist/fancybox.css","selector":".swiper-slide img"});
  }
  if ('false' == 'true') {
    stellar.plugins.heti = Object.assign({"enable":false,"css":"https://unpkg.com/heti/umd/heti.min.css","js":"https://unpkg.com/heti/umd/heti-addon.min.js"});
  }
</script>

<!-- required -->

  
<script src="/js/main.js" async></script>



<!-- optional -->

  <script>
  function loadBeaudar() {
    const els = document.querySelectorAll("#comments #beaudar");
    if (els.length === 0) return;
    els.forEach((el, i) => {
      try {
        el.innerHTML = '';
      } catch (error) {
        console.log(error);
      }
      var script = document.createElement('script');
      script.src = 'https://beaudar.lipk.org/client.js';
      script.async = true;
      for (let key of Object.keys(el.attributes)) {
        let attr = el.attributes[key];
        if (['class', 'id'].includes(attr.name) === false) {
          script.setAttribute(attr.name, attr.value);
        }
      }
      el.appendChild(script);
    });
  }
  window.addEventListener('DOMContentLoaded', (event) => {
      loadBeaudar();
  });
</script>




<!-- inject -->


  </div>
</body>
</html>
